{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder\n",
    "mission_path = os.path.join(Path().home(), \"digiforest_mission_data/latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other params\n",
    "base_inverted = True\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = 1 / 2.54\n",
    "plot_width = 8.89 * cm\n",
    "plot_height = 4 * cm\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pose files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "\n",
    "def read_poses_file(filename, base_inverted=False):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Generate timestamp from sec and nsec\n",
    "    ts = 1e9 * df[\"sec\"] + df[\"nsec\"]  # In nanoseconds\n",
    "    df.index = pd.to_datetime(ts)\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "    # Parse data\n",
    "    poses = {}\n",
    "    for ts, x, y, z, qx, qy, qz, qw in zip(\n",
    "        df.index, df[\"x\"], df[\"y\"], df[\"z\"], df[\"qx\"], df[\"qy\"], df[\"qz\"], df[\"qw\"]\n",
    "    ):\n",
    "        poses[f\"{ts:.10f}\"] = np.eye(4)\n",
    "        poses[f\"{ts:.10f}\"][0:3, 3] = np.array([x, y, z])\n",
    "        poses[f\"{ts:.10f}\"][0:3, 0:3] = R.from_quat([qx, qy, qz, qw]).as_matrix()\n",
    "\n",
    "        # TODO: fix base inversion\n",
    "\n",
    "    return df, poses\n",
    "\n",
    "\n",
    "df_state_poses, poses_list = read_poses_file(\n",
    "    os.path.join(mission_path, \"states/state_pose_data.csv\"), base_inverted=base_inverted\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load twist files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_twist_file(filename, base_inverted=False):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Generate timestamp from sec and nsec\n",
    "    ts = 1e9 * df[\"sec\"] + df[\"nsec\"]  # In nanoseconds\n",
    "    df.index = pd.to_datetime(ts)\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "    # Correct twist due to base inversion\n",
    "    if base_inverted:\n",
    "        df[\"vx\"] *= -1\n",
    "        df[\"vy\"] *= -1\n",
    "\n",
    "    # Speeds\n",
    "    df[\"lin_speed\"] = (df[\"vx\"] ** 2 + df[\"vy\"] ** 2).pow(1.0 / 2)\n",
    "    df[\"ang_speed\"] = df[\"wz\"].abs()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_state_twist = read_twist_file(\n",
    "    os.path.join(mission_path, \"states/state_twist_data.csv\"), base_inverted=base_inverted\n",
    ")\n",
    "df_reference_twist = read_twist_file(\n",
    "    os.path.join(mission_path, \"states/reference_twist_data.csv\"), base_inverted=base_inverted\n",
    ")\n",
    "df_operator_twist = read_twist_file(\n",
    "    os.path.join(mission_path, \"states/operator_twist_data.csv\"), base_inverted=base_inverted\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read other operator signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_frames = [\"base_vilens\", \"map_vilens\"]\n",
    "query_frames = [\"LF_FOOT\", \"RF_FOOT\", \"LH_FOOT\", \"RH_FOOT\"]\n",
    "\n",
    "df_tf = {}\n",
    "for parent in reference_frames:\n",
    "    for child in query_frames:\n",
    "        prefix = f\"{parent}_{child}\"\n",
    "        df, poses = read_poses_file(\n",
    "            os.path.join(mission_path, f\"states/{prefix}_data.csv\"), base_inverted=base_inverted\n",
    "        )\n",
    "        \n",
    "        df_tf[prefix] = df.copy(deep=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all indices\n",
    "joined_indices = pd.Index(df_tf[prefix].index)\n",
    "for k,v in df_tf.items():\n",
    "  joined_indices = joined_indices.union(v.index)\n",
    "\n",
    "joined_indices = joined_indices.drop_duplicates()\n",
    "\n",
    "for k,v in df_tf.items():\n",
    "  df_tf[k] = df_tf[k].reindex(index=joined_indices, )\n",
    "  df_tf[k] = df_tf[k].interpolate(method=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plot_width = 20 * cm\n",
    "plot_height = 5 * cm\n",
    "fig, ax = plt.subplots(\n",
    "    1, 1, figsize=(plot_width, plot_height), constrained_layout=False, dpi=300\n",
    ")\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "import scipy.signal as signal\n",
    "\n",
    "# plt.plot(df_tf[\"base_vilens_LF_FOOT\"][\"z\"][200:500].rolling(1, center=True).median())\n",
    "# plt.plot(df_tf[\"base_vilens_LF_FOOT\"][\"z\"][200:500].diff().rolling(3, center=True).mean())\n",
    "# plt.plot(df_tf[\"base_vilens_LF_FOOT\"][\"z\"][0:300].rolling(3, center=True).mean())\n",
    "# plt.plot(df_tf[\"base_vilens_RF_FOOT\"][\"z\"][100:300])\n",
    "# plt.plot(df_tf[\"base_vilens_LH_FOOT\"][\"z\"][100:300])\n",
    "# plt.plot(df_tf[\"base_vilens_RH_FOOT\"][\"z\"][100:300])\n",
    "\n",
    "total_footsteps = 0\n",
    "footsteps = {}\n",
    "for foot in [\"LF_FOOT\", \"RF_FOOT\", \"LH_FOOT\", \"RH_FOOT\"]:\n",
    "    prefix = f\"base_vilens_{foot}\"\n",
    "    off = 0\n",
    "    dt = -1\n",
    "    y = df_tf[prefix][\"z\"][off:off+dt]\n",
    "    sy = df_tf[prefix][\"z\"].rolling(5, center=True).mean()[off:off+dt]\n",
    "    t = df_tf[prefix][\"z\"].index[off:off+dt]\n",
    "\n",
    "    peaks, _ = signal.find_peaks(-sy, distance=10, prominence=0.01)\n",
    "    footsteps[foot] = peaks\n",
    "    # ax.plot(t, y, linewidth=0.5)\n",
    "    # ax.plot(t, sy, linewidth=0.5)\n",
    "    # ax.plot(t[peaks], y[peaks], marker=\"x\", linewidth=0)\n",
    "    total_footsteps += peaks.size\n",
    "\n",
    "    print(f\"num_footsteps: {peaks.size}\")\n",
    "\n",
    "for foot,v in foot_steps.items():\n",
    "    prefix = f\"map_vilens_{foot}\"\n",
    "    ax.scatter(df_tf[prefix][\"x\"][v], df_tf[prefix][\"y\"][v], s=2, marker=\"o\", edgecolor=\"none\", alpha=0.5)\n",
    "\n",
    "foot_radius = 0.03 # meters\n",
    "foot_area = np.pi * foot_radius**2\n",
    "\n",
    "total_footprint = total_footsteps * foot_area\n",
    "print(f\"steps: {total_footsteps}\")\n",
    "print(f\"area_impacted: {total_footprint:.4f} m^2\")\n",
    "\n",
    "# nout = 100\n",
    "# w = np.linspace(0.001, 10, nout)\n",
    "# pgram = signal.lombscargle(df_tf[\"base_vilens_LF_FOOT\"][\"z\"].index[0:300], df_tf[\"base_vilens_LF_FOOT\"][\"z\"][0:300], w)\n",
    "# plt.plot(pgram)\n",
    "# plt.show()\n",
    "# pgram\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SLAM graph\n",
    "Required for distance computation and coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slam, slam_graph = read_poses_file(\n",
    "    os.path.join(mission_path, \"states/slam_graph_data.csv\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend indices\n",
    "joined_indices = df_state_twist.index.union(df_reference_twist.index).drop_duplicates()\n",
    "joined_indices = joined_indices.union(df_operator_twist.index).drop_duplicates()\n",
    "\n",
    "df_state_twist = df_state_twist.reindex(index=joined_indices)\n",
    "df_state_twist = df_state_twist.interpolate(method=\"index\")\n",
    "\n",
    "df_reference_twist = df_reference_twist.reindex(index=joined_indices)\n",
    "df_reference_twist = df_reference_twist.interpolate(method=\"index\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operator interventions\n",
    "This is required for autonomy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interventions from safety officer\n",
    "df_state_twist[\"safety_intervention\"] = df_operator_twist[\"lin_speed\"] > 0.01\n",
    "df_state_twist[\"safety_intervention\"] = df_state_twist[\n",
    "    \"safety_intervention\"\n",
    "].interpolate(method=\"pad\")\n",
    "\n",
    "# Interventions from forestry operator\n",
    "\n",
    "\n",
    "# Total interventions\n",
    "df_state_twist[\"interventions\"] = df_state_twist[\"safety_intervention\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate covered area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odom_points = df_state_poses[[\"x\", \"y\"]].to_numpy()\n",
    "slam_points = df_slam[[\"x\", \"y\"]].to_numpy()\n",
    "\n",
    "import shapely\n",
    "import shapely.plotting\n",
    "\n",
    "sp_odom_points = shapely.MultiPoint(odom_points)\n",
    "\n",
    "sp_slam_points = shapely.MultiPoint(slam_points)\n",
    "sp_slam_hull = sp_slam_points.convex_hull\n",
    "\n",
    "sensor_range = 30 / 2\n",
    "\n",
    "sp_sensing_hull = sp_slam_hull.buffer(sensor_range)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ts = df_state_twist.index[0]\n",
    "\n",
    "df_state_poses.index = df_state_poses.index - ref_ts\n",
    "df_state_twist.index = df_state_twist.index - ref_ts\n",
    "df_reference_twist.index = df_reference_twist.index - ref_ts\n",
    "df_operator_twist.index = df_operator_twist.index - ref_ts\n",
    "df_slam.index = df_slam.index - ref_ts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mission statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as integrate\n",
    "\n",
    "stats = {}\n",
    "\n",
    "# Constants\n",
    "stats[\"sqm_to_ha\"] = 0.0001\n",
    "stats[\"sec_to_min\"] = 1 / 60\n",
    "stats[\"sec_to_hour\"] = 1 / 3600\n",
    "\n",
    "# Speed\n",
    "stats[\"max_lin_speed\"] = df_state_twist[\"lin_speed\"].max().item()\n",
    "stats[\"min_lin_speed\"] = df_state_twist[\"lin_speed\"].min().item()\n",
    "stats[\"mean_lin_speed\"] = df_state_twist[\"lin_speed\"].mean().item()\n",
    "stats[\"std_lin_speed\"] = df_state_twist[\"lin_speed\"].std().item()\n",
    "\n",
    "stats[\"mean_ang_speed\"] = df_state_twist[\"ang_speed\"].mean().item()\n",
    "stats[\"std_ang_speed\"] = df_state_twist[\"ang_speed\"].std().item()\n",
    "\n",
    "# Distance walked\n",
    "stats[\"distance_m\"] = (\n",
    "    df_slam[[\"x\", \"y\", \"z\"]]\n",
    "    .diff()\n",
    "    .apply(lambda values: sum([v**2 for v in values]), axis=1)\n",
    "    .sum()\n",
    ").item()\n",
    "\n",
    "# Mission time\n",
    "stats[\"time_sec\"] = (df_slam.index[-1] - df_slam.index[0]).total_seconds()\n",
    "\n",
    "# Interventions\n",
    "stats[\"interventions\"] = integrate.simpson(\n",
    "    df_state_twist[\"interventions\"], df_state_twist.index.total_seconds()\n",
    ").item()\n",
    "\n",
    "# Percentaje of interventions\n",
    "stats[\"interventions_perc\"] = stats[\"interventions\"] / stats[\"time_sec\"] * 100\n",
    "\n",
    "# Area covered\n",
    "stats[\"area_m2\"] = sp_slam_hull.area\n",
    "stats[\"area_ha\"] = sp_slam_hull.area * stats[\"sqm_to_ha\"]\n",
    "stats[\"sensor_range_m\"] = sensor_range\n",
    "stats[\"sensed_area_m2\"] = sp_sensing_hull.area\n",
    "stats[\"sensed_area_ha\"] = sp_sensing_hull.area * stats[\"sqm_to_ha\"]\n",
    "\n",
    "# Hectares per second\n",
    "stats[\"ha_per_sec\"] = stats[\"area_m2\"] / stats[\"time_sec\"]\n",
    "stats[\"ha_per_min\"] = stats[\"area_m2\"] / (stats[\"time_sec\"] * stats[\"sec_to_min\"])\n",
    "stats[\"ha_per_hour\"] = stats[\"area_m2\"] / (stats[\"time_sec\"] * stats[\"sec_to_hour\"])\n",
    "\n",
    "# Print\n",
    "for k, v in stats.items():\n",
    "    print(f\"{k:>20}: {v:<20.4f}\")\n",
    "\n",
    "\n",
    "# Save as YAML\n",
    "import yaml\n",
    "file=open(os.path.join(mission_path, \"mission_report.yaml\"),\"w\")\n",
    "yaml.dump(stats, file)\n",
    "file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covered area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plot_width = 15 * cm\n",
    "plot_height = 5 * cm\n",
    "fig, ax = plt.subplots(\n",
    "    1, 1, figsize=(plot_width, plot_height), constrained_layout=False, dpi=300\n",
    ")\n",
    "plt.grid(axis=\"both\", color=\"0.8\", linewidth=0.3)\n",
    "\n",
    "# Plot points\n",
    "shapely.plotting.plot_points(sp_slam_points, markersize=0.5, marker=\"o\", color=(0.1, 0.1, 0.1), fillstyle=\"full\")\n",
    "shapely.plotting.plot_points(sp_odom_points, markersize=0.1, marker=\"o\", color=(1.0, 0.1, 0.1), fillstyle=\"full\")\n",
    "\n",
    "# Plot sensor polygon\n",
    "shapely.plotting.plot_polygon(\n",
    "    sp_slam_hull.buffer(sensor_range * 0.25),\n",
    "    add_points=False,\n",
    "    color=(0, 0.5, 1),\n",
    "    linewidth=0,\n",
    "    alpha=0.1,\n",
    ")\n",
    "shapely.plotting.plot_polygon(\n",
    "    sp_slam_hull.buffer(sensor_range * 0.50),\n",
    "    add_points=False,\n",
    "    color=(0, 0.5, 1),\n",
    "    linewidth=0,\n",
    "    alpha=0.1,\n",
    ")\n",
    "shapely.plotting.plot_polygon(\n",
    "    sp_slam_hull.buffer(sensor_range * 0.75),\n",
    "    add_points=False,\n",
    "    color=(0, 0.5, 1),\n",
    "    linewidth=0,\n",
    "    alpha=0.1,\n",
    ")\n",
    "shapely.plotting.plot_polygon(\n",
    "    sp_slam_hull.buffer(sensor_range * 1.00),\n",
    "    add_points=False,\n",
    "    color=(0, 0.5, 1),\n",
    "    linewidth=0,\n",
    "    alpha=0.1,\n",
    ")\n",
    "# shapely.plotting.plot_polygon(hull, add_points=False)\n",
    "\n",
    "ax.set_xlabel(\"x [m]\")\n",
    "ax.set_ylabel(\"y [m]\")\n",
    "ax.margins(x=0.1, y=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robot velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_window=\"1000ms\"\n",
    "linewidth = 0.8\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    1, 1, figsize=(plot_width, plot_height), constrained_layout=False, dpi=300\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    df_state_twist.index.total_seconds(),\n",
    "    df_state_twist[\"lin_speed\"].rolling(smoothing_window, center=True).mean(),\n",
    "    label=\"Robot speed\",\n",
    "    linewidth=linewidth,\n",
    ")\n",
    "plt.plot(\n",
    "    df_reference_twist.index.total_seconds(),\n",
    "    df_reference_twist[\"lin_speed\"].rolling(smoothing_window, center=True).mean(),\n",
    "    label=\"Reference command\",\n",
    "    linewidth=linewidth,\n",
    ")\n",
    "plt.plot(\n",
    "    df_operator_twist.index.total_seconds(),\n",
    "    df_operator_twist[\"lin_speed\"].rolling(smoothing_window, center=True).mean(),\n",
    "    label=\"Operator command\",\n",
    "    linewidth=linewidth,\n",
    ")\n",
    "\n",
    "ax.legend(edgecolor=(1, 1, 1, 0), framealpha=0.9, loc=(0, 1.1), ncol=2)\n",
    "# ax.set_title('Computation Time')\n",
    "ax.set_xlabel(\"Time [s]\")\n",
    "ax.set_ylabel(\"Speed [m/s]\")\n",
    "ax.margins(x=0)\n",
    "\n",
    "# Export\n",
    "fig.set_tight_layout(True)\n",
    "fig.savefig(os.path.join(mission_path, \"mission_velocity.pdf\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autonomy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
